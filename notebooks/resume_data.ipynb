{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808c14f9",
   "metadata": {},
   "source": [
    "# Identifying Resume Data Structure\n",
    "\n",
    "## Jake's Resume\n",
    "Jake's Resume is a very popular resume for SWE Roles, and widely used by developers as base in the process of writing the resume.\n",
    "\n",
    "**Topics**:\n",
    "- Education: Describes the formal education of the candidate, e.g. Bachelor's Degree, Masters' Degree and others.\n",
    "    - School/University\n",
    "    - Location\n",
    "    - Course Description/Title/Type\n",
    "    - Start Date - Conclusion Date\n",
    " - Experience: Describes the formal work experiences of the candidate\n",
    "    - Title of Job\n",
    "    - Company Name\n",
    "    - Start Date - End Date\n",
    "    - Location\n",
    "    - Relevant Topics\n",
    "        - Each topic is described as bullet point, usually with XYZ or STAR model\n",
    "- Projects: Describes the personal or college projects that the candidate developed\n",
    "    - Title of the Project\n",
    "    - Tech Stack\n",
    "    - Start Date - End Date\n",
    "    - Relevant Topics\n",
    "        - Each topic is described as bullet point, usually with XYZ or STAR model\n",
    "- Technical Skills\n",
    "    - Languages: Programming Languages used\n",
    "    - Frameworks\n",
    "    - Developer Tools\n",
    "    - Libraries\n",
    "\n",
    "## FAANGPath Resume\n",
    "FAANGPath Resume is a very popular resume for FAANG entry-level/intern roles.\n",
    "\n",
    "**Topics**:\n",
    "- Objective: Gives a introduction of candidate and the objective related to career/job seek\n",
    "- Education: Describes the formal education of the candidate, e.g. Bachelor's Degree, Masters' Degree and others.\n",
    "    - Course Description/Title/Type\n",
    "    - School/University\n",
    "    - Location\n",
    "    - Start Date - Conclusion Date\n",
    "    - Relevant Coursework\n",
    "- Skills\n",
    "    - Technical Skills\n",
    "    - Soft Skills\n",
    "    - XPTO\n",
    " - Experience: Describes the formal work experiences of the candidate\n",
    "    - Title of Job\n",
    "    - Company Name\n",
    "    - Start Date - End Date\n",
    "    - Location\n",
    "    - Relevant Topics\n",
    "        - Each topic is described as bullet point, usually with XYZ or STAR model\n",
    "- Projects: Describes the personal or college projects that the candidate developed\n",
    "    - Title of the Project\n",
    "    - Description of the Project\n",
    "- Extra-curricular Activities\n",
    "- Leadership\n",
    "\n",
    "## Engineering Resume\n",
    "- Skills\n",
    "    - [Field]: Skills, XPTO\n",
    "- Experience: Describes the formal work experiences of the candidate\n",
    "    - Title of Job\n",
    "    - Company Name\n",
    "    - Start Date - End Date\n",
    "    - Location\n",
    "    - Relevant Topics\n",
    "        - Each topic is described as bullet point, usually with XYZ or STAR model\n",
    "- Projects: Describes the personal or college projects that the candidate developed\n",
    "    - Title of the Project\n",
    "    - Project Link\n",
    "    - Relevant Topics\n",
    "        - Each topic is described as bullet point, usually with XYZ or STAR model\n",
    "- Education: Describes the formal education of the candidate, e.g. Bachelor's Degree, Masters' Degree and others.\n",
    "    - Course Description/Title/Type\n",
    "    - School/University\n",
    "    - Start Date - Conclusion Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install the project libraries and setup the environment, run the commands below\n",
    "# %uv pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0e6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, HttpUrl, EmailStr, ConfigDict\n",
    "\n",
    "class BaseSchema(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        populate_by_name=True,\n",
    "        extra='ignore', \n",
    "        str_strip_whitespace=True\n",
    "    )\n",
    "\n",
    "class Location(BaseSchema):\n",
    "    city: Optional[str] = None\n",
    "    state: Optional[str] = None\n",
    "    country_code: Optional[str] = Field(None, alias=\"countryCode\") # We must use ISO 3166-1 alpha-2\n",
    "\n",
    "class Profile(BaseSchema):\n",
    "    network: str = Field(..., description=\"LinkedIn, GitHub, Portfolio\")\n",
    "    username: Optional[str] = None\n",
    "    url: Optional[HttpUrl] = None\n",
    "\n",
    "class Basics(BaseSchema):\n",
    "    name: str\n",
    "    label: Optional[str] = Field(None, description=\"Target role, e.g.: Software Engineer\")\n",
    "    email: Optional[EmailStr] = None\n",
    "    phone: Optional[str] = None\n",
    "    summary: Optional[str] = Field(None, description=\"Professional summary or Objective\")\n",
    "    location: Optional[Location] = None\n",
    "    profiles: List[Profile] = Field(default_factory=list)\n",
    "\n",
    "class Education(BaseSchema):\n",
    "    institution: str\n",
    "    area: str\n",
    "    study_type: str = Field(..., alias=\"studyType\", description=\"Bachelor, Master, etc.\")\n",
    "    start_date: Optional[str] = Field(None, alias=\"startDate\")\n",
    "    end_date: Optional[str] = Field(None, alias=\"endDate\")\n",
    "    score: Optional[str] = Field(None, description=\"GPA or average, e.g.: 9.5\")\n",
    "    courses: List[str] = Field(default_factory=list, description=\"Relevant Coursework\")\n",
    "\n",
    "class Work(BaseSchema):\n",
    "    name: str = Field(..., description=\"Company name\")\n",
    "    position: str\n",
    "    url: Optional[HttpUrl] = None\n",
    "    start_date: Optional[str] = Field(None, alias=\"startDate\")\n",
    "    end_date: Optional[str] = Field(None, alias=\"endDate\") # String to accept 'Current'\n",
    "    summary: Optional[str] = None\n",
    "    highlights: List[str] = Field(default_factory=list, description=\"Bullets with STAR Method\")\n",
    "\n",
    "class Project(BaseSchema):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    highlights: List[str] = Field(default_factory=list)\n",
    "    keywords: List[str] = Field(default_factory=list, description=\"Tech stack used in the project\")\n",
    "    url: Optional[HttpUrl] = None\n",
    "    start_date: Optional[str] = Field(None, alias=\"startDate\")\n",
    "    end_date: Optional[str] = Field(None, alias=\"endDate\")\n",
    "\n",
    "class Skill(BaseSchema):\n",
    "    name: str = Field(..., description=\"Category: Languages, Frameworks, Soft Skills\")\n",
    "    level: Optional[str] = None # Advanced, Intermediate\n",
    "    keywords: List[str] = Field(default_factory=list, description=\"List: Python, AWS, Docker\")\n",
    "\n",
    "class Award(BaseSchema):\n",
    "    title: str\n",
    "    date: Optional[str] = None\n",
    "    awarder: Optional[str] = None\n",
    "    summary: Optional[str] = None\n",
    "\n",
    "\n",
    "class ResumeSchema(BaseSchema):\n",
    "    basics: Basics\n",
    "    work: List[Work] = Field(default_factory=list)\n",
    "    education: List[Education] = Field(default_factory=list)\n",
    "    awards: List[Award] = Field(default_factory=list)\n",
    "    projects: List[Project] = Field(default_factory=list)\n",
    "    skills: List[Skill] = Field(default_factory=list)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def all_hard_skills(self) -> set[str]:\n",
    "        skill_set = set()\n",
    "        \n",
    "        # 1. Get from explicit Skills section\n",
    "        for skill_group in self.skills:\n",
    "            for kw in skill_group.keywords:\n",
    "                skill_set.add(kw.lower())\n",
    "        \n",
    "        # 2. Get from Projects keywords\n",
    "        for proj in self.projects:\n",
    "            for kw in proj.keywords:\n",
    "                skill_set.add(kw.lower())\n",
    "                \n",
    "        return skill_set\n",
    "\n",
    "    @property\n",
    "    def full_experience_text(self) -> str:\n",
    "        texts = []\n",
    "        for job in self.work:\n",
    "            texts.extend(job.highlights)\n",
    "        for proj in self.projects:\n",
    "            texts.extend(proj.highlights)\n",
    "        return \" \".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b0e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basics': {'name': 'Ricardo Fernandes', 'label': 'Software Engineer', 'email': 'ricardoviniciusaf@gmail.com', 'location': {'city': 'Maceió', 'state': 'AL', 'countryCode': 'BR'}, 'profiles': [{'network': 'LinkedIn', 'username': 'ricardovini', 'url': 'https://linkedin.com/in/ricardovini'}, {'network': 'GitHub', 'username': 'ricardovinicius', 'url': 'https://github.com/ricardovinicius'}]}, 'work': [{'name': 'Centro de Inovação EDGE', 'position': 'Software Engineer', 'startDate': '2023-07', 'endDate': 'Current', 'highlights': ['Developed a client environment simulation application (FastAPI and Vue.js) used for end-to-end testing of an RPA application', 'Worked on the development of a REST API using FastAPI for monitoring and managing custom RPA bots, ensuring real-time visibility and greater operational control over automations', 'Participated in integrating RPA workflows with RAG pipelines and LLMs, contributing to the automation of multilingual document processing and analysis', 'Refactored a FastAPI backend to increase code testability and cohesion by applying Service, Repository, and Dependency Injection patterns', 'Contributed to increasing test coverage of a Python codebase to 90% by creating and maintaining unit tests with unittest, helping reduce failures in the final product', 'Responsible for implementing an observability solution combining structured logs (logfmt and JSON) for event analysis and Sentry for error tracking and aggregation', 'Implemented a messaging pipeline with RabbitMQ for asynchronous processing of ML/LLM jobs between microservices, ensuring delivery and decoupling', \"Participated in deploying applications to the client's internal environment, ensuring security and quality standards through containerization (Docker), CI/CD pipeline creation (GitLab), and Kubernetes orchestration\"]}], 'education': [{'institution': 'Federal University of Alagoas', 'area': 'Computer Science', 'studyType': 'Bachelor of Science', 'startDate': '2022-08', 'endDate': '2027-07'}], 'projects': [{'name': 'Odontolog', 'description': 'Backend development for a university dental school clinic management system.', 'keywords': ['Java', 'Spring Boot', 'PostgreSQL', 'Docker'], 'startDate': '2025', 'highlights': ['Collaborated on the backend development of a Java/Spring Boot application, responsible for providing a REST API and implementing business rules', 'Defined the service architecture and backend data modeling, ensuring decoupling and component reusability', 'Integrated the backend with S3-compatible storage services for secure patient document storage via pre-signed URLs', 'Implemented unit and integration tests in JUnit to ensure application stability']}], 'skills': [{'name': 'Languages', 'keywords': ['Python', 'Java', 'C', 'C++', 'SQL', 'JavaScript', 'HTML', 'CSS']}, {'name': 'Frameworks', 'keywords': ['FastAPI', 'Spring Boot', 'Vue.js', 'React', 'LangChain', 'Robot Framework']}, {'name': 'Tools', 'keywords': ['Git', 'Docker', 'GitLab CI', 'Kubernetes', 'RabbitMQ']}, {'name': 'Libraries', 'keywords': ['JUnit', 'Pytest', 'Pydantic', 'unittest', 'pika', 'FastStream']}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load resume data\n",
    "RESUME_PATH = \"data/resumes/myResume.json\"\n",
    "\n",
    "with open(RESUME_PATH, \"r\") as f:\n",
    "    resume_json = json.load(f)\n",
    "\n",
    "print(resume_json)\n",
    "\n",
    "resume_data = ResumeSchema(**resume_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f00e2",
   "metadata": {},
   "source": [
    "# Identifying Job Data Structure\n",
    "\n",
    "- Job Title\n",
    "    - Role\n",
    "    - Specification\n",
    "    - Level/Seniority\n",
    "- Work Model (e.g. On-site, Remote, Hybrid, Flexible)\n",
    "- Location\n",
    "- Key Responsabilities\n",
    "- Key Requirements / What we expect of you\n",
    "    - Tech Stack\n",
    "    - Experience Time\n",
    "    - Education/Degree\n",
    "    - Soft Skills can be here too\n",
    "- Nice to Have / Preferred Qualifications / Bonus Points\n",
    "- Soft Skills\n",
    "- Benefits / What we Offer\n",
    "- Tech Stack / Keywords - Extract from Key Responsabilities, Requirements and Good to Have\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b6340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "class SeniorityLevel(Enum):\n",
    "    INTERN = 0\n",
    "    JR = 1\n",
    "    MID = 2\n",
    "    SENIOR = 3\n",
    "    STAFF = 4\n",
    "    LEAD = 5\n",
    "\n",
    "\n",
    "class JobWorkplace(BaseModel):\n",
    "    model: Literal['remote', 'hybrid', 'onsite']\n",
    "    country: str = \"BR\" # We must use ISO 3166-1 alpha-2\n",
    "    state: Optional[str] = None\n",
    "    city: Optional[str] = None\n",
    "\n",
    "class SalaryRange(BaseModel):\n",
    "    currency: str = \"BRL\"\n",
    "    min_amount: Optional[float] = None\n",
    "    max_amount: Optional[float] = None\n",
    "    frequency: Literal['monthly', 'yearly', 'hourly'] = 'monthly'\n",
    "\n",
    "\n",
    "class JobPostingSchema(BaseModel):\n",
    "    # 1. Job Basic Information\n",
    "    title: str\n",
    "    company_name: str\n",
    "    original_url: Optional[str] = None\n",
    "    \n",
    "    # 2. Seniority (List, as it can be 'Jr', 'Mid', 'Senior', 'Staff', 'Lead', 'Intern')\n",
    "    seniority_level: List[SeniorityLevel] = Field(..., description=\"List of accepted seniority levels\")\n",
    "    \n",
    "    # 3. Logistics (List, as it can be 'Hybrid' OR 'Remote')\n",
    "    work_options: List[JobWorkplace] = Field(..., description=\"Accepted work model options\")\n",
    "\n",
    "    # 4. Hard Requirements (For Mathematical Match)\n",
    "    # This is where \"Tech Stack / Keywords - Extract\" fits in\n",
    "    required_hard_skills: List[str] = Field(default_factory=list, description=\"Normalized mandatory skills\")\n",
    "    nice_to_have_skills: List[str] = Field(default_factory=list, description=\"Nice-to-have skills (Bonus Points)\")\n",
    "    \n",
    "    min_experience_years: int = Field(0, description=\"Minimum years of experience required\")\n",
    "    degree_required: bool = Field(False, description=\"Whether a formal higher education degree is required\")\n",
    "    languages: List[str] = Field(default_factory=list, description=\"e.g., ['Advanced English']\")\n",
    "\n",
    "    # 5. Semantic Context (For LLM processing)\n",
    "    # Includes \"Key Responsibilities\", \"Soft Skills\", and \"Description\"\n",
    "    key_responsibilities: List[str] = Field(..., description=\"Summary focused on responsibilities and challenges\")\n",
    "    soft_skills_context: List[str] = Field(default_factory=list, description=\"List of soft skills for profile analysis\")\n",
    "    \n",
    "    # 6. Benefits (For display only, does not affect score)\n",
    "    benefits_text: Optional[str] = None\n",
    "    salary: Optional[SalaryRange] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e05da",
   "metadata": {},
   "source": [
    "Using LLM-based strategy to parse job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cd26ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Engenheiro de Software Junior ou Pleno (Java) | Investment Products' company_name='BTG Pactual' original_url=None seniority_level=[<SeniorityLevel.JR: 1>, <SeniorityLevel.MID: 2>] work_options=[JobWorkplace(model='hybrid', country='BR', state='SP', city='São Paulo')] required_hard_skills=['Java', 'Spring Boot', 'Web Services', 'REST', 'SOAP', 'Mensageria', 'Kubernetes', 'AWS', 'Docker', 'Oracle', 'PostgreSQL', 'DynamoDB', 'CI/CD', 'Git', 'Jenkins', 'Github Actions'] nice_to_have_skills=['Node'] min_experience_years=0 degree_required=True languages=[] key_responsibilities=['Referência técnica e atuação junto à equipe de projetos que utiliza em seu trabalho algumas tecnologias como Java, Spring Boot, WebServices REST/SOAP, Mensageria, Kubernetes e AWS.', 'Trabalhar com arquitetura orientada a microsserviços, modelo DevOps e experiência com troubleshooting e análise de logs.', 'Desenvolver e expandir do pipeline de produtos do Portal de Clientes do BTG e soluções para a plataforma administrativa', 'Atuar nos projetos que consistem em aumentar e flexibilizar produtos disponíveis na plataforma Digital.'] soft_skills_context=['comunicação', 'resiliência', 'analítica', 'crescimento profissional', 'superar desafios', 'inovação'] benefits_text='Participação nos Lucros e Resultados (PLR);\\nAuxílio Alimentação e Refeição;\\nPlano Médico;\\nPlano Odontológico;\\nAuxílio Creche/Babá;\\nVale Transporte;\\nWellHub;\\nTotalPass;\\nPrograma de Apoio Pessoal (EAP);\\nPlanos por adesão como Previdência Privada e Seguro de Vida;\\nDesconto em Farmácia;\\nPrograma de Nutrição;\\nPrograma de Gestantes;\\nLicença Maternidade e Paternidade Estendida – empresa Cidadã.' salary=None\n",
      "DEBUG: ChatCompletion(id='xPaDabnXNf7fz7IPoM-g4Qo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"title\": \"Engenheiro de Software Junior ou Pleno (Java) | Investment Products\",\\n  \"company_name\": \"BTG Pactual\",\\n  \"original_url\": null,\\n  \"seniority_level\": [\\n    1,\\n    2\\n  ],\\n  \"work_options\": [\\n    {\\n      \"model\": \"hybrid\",\\n      \"country\": \"BR\",\\n      \"state\": \"SP\",\\n      \"city\": \"São Paulo\"\\n    }\\n  ],\\n  \"required_hard_skills\": [\\n    \"Java\",\\n    \"Spring Boot\",\\n    \"Web Services\",\\n    \"REST\",\\n    \"SOAP\",\\n    \"Mensageria\",\\n    \"Kubernetes\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Oracle\",\\n    \"PostgreSQL\",\\n    \"DynamoDB\",\\n    \"CI/CD\",\\n    \"Git\",\\n    \"Jenkins\",\\n    \"Github Actions\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Node\"\\n  ],\\n  \"min_experience_years\": 0,\\n  \"degree_required\": true,\\n  \"languages\": [],\\n  \"key_responsibilities\": [\\n    \"Referência técnica e atuação junto à equipe de projetos que utiliza em seu trabalho algumas tecnologias como Java, Spring Boot, WebServices REST/SOAP, Mensageria, Kubernetes e AWS.\",\\n    \"Trabalhar com arquitetura orientada a microsserviços, modelo DevOps e experiência com troubleshooting e análise de logs.\",\\n    \"Desenvolver e expandir do pipeline de produtos do Portal de Clientes do BTG e soluções para a plataforma administrativa\",\\n    \"Atuar nos projetos que consistem em aumentar e flexibilizar produtos disponíveis na plataforma Digital.\"\\n  ],\\n  \"soft_skills_context\": [\\n    \"comunicação\",\\n    \"resiliência\",\\n    \"analítica\",\\n    \"crescimento profissional\",\\n    \"superar desafios\",\\n    \"inovação\"\\n  ],\\n  \"benefits_text\": \"Participação nos Lucros e Resultados (PLR);\\\\nAuxílio Alimentação e Refeição;\\\\nPlano Médico;\\\\nPlano Odontológico;\\\\nAuxílio Creche/Babá;\\\\nVale Transporte;\\\\nWellHub;\\\\nTotalPass;\\\\nPrograma de Apoio Pessoal (EAP);\\\\nPlanos por adesão como Previdência Privada e Seguro de Vida;\\\\nDesconto em Farmácia;\\\\nPrograma de Nutrição;\\\\nPrograma de Gestantes;\\\\nLicença Maternidade e Paternidade Estendida – empresa Cidadã.\",\\n  \"salary\": null\\n}\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1770256068, model='gemma-3-12b-it', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=0, prompt_tokens=2026, total_tokens=2026, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "JOB_TEXT_PATH = \"data/jobs/texts/btg.txt\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = instructor.from_openai(\n",
    "    OpenAI(\n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "    ),\n",
    "    mode=instructor.Mode.JSON_O1, \n",
    ")\n",
    "\n",
    "with open(JOB_TEXT_PATH, \"r\") as f:\n",
    "    job_text = f.read()\n",
    "\n",
    "def extract_job_data(job_text):\n",
    "    prompt = \"\"\"Extract detailed data from this Job Description:\\n\\n{job_text}\"\"\"\n",
    "\n",
    "    response_data, response_raw = client.chat.completions.create_with_completion(\n",
    "        model=\"gemma-3-12b-it\",\n",
    "        response_model=JobPostingSchema,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt.format(job_text=job_text)},\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "    print(response_data)\n",
    "    print(f\"DEBUG: {response_raw}\")\n",
    "\n",
    "    return response_data\n",
    "\n",
    "job_posting_data = extract_job_data(job_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90aab223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'postgresql': ['postgres', 'pgsql', 'postgre', 'postgresql db'], 'postgres': ['postgresql'], 'pgsql': ['postgresql'], 'postgre': ['postgresql'], 'postgresql db': ['postgresql'], 'mysql': ['my-sql', 'mysql db'], 'my-sql': ['mysql'], 'mysql db': ['mysql'], 'mongodb': ['mongo', 'mongo db', 'mongodb atlas'], 'mongo': ['mongodb'], 'mongo db': ['mongodb'], 'mongodb atlas': ['mongodb'], 'microsoft sql server': ['mssql', 'sql server', 'ms sql'], 'mssql': ['microsoft sql server'], 'sql server': ['microsoft sql server'], 'ms sql': ['microsoft sql server'], 'sqlite': ['sqlite3', 'sqlite db'], 'sqlite3': ['sqlite'], 'sqlite db': ['sqlite'], 'redis': ['redis db', 'redis cache'], 'redis db': ['redis'], 'redis cache': ['redis'], 'elasticsearch': ['elastic', 'elk stack', 'es'], 'elastic': ['elasticsearch'], 'elk stack': ['elasticsearch'], 'es': ['elasticsearch'], 'cassandra': ['apache cassandra'], 'apache cassandra': ['cassandra'], 'dynamodb': ['aws dynamodb', 'dynamo'], 'aws dynamodb': ['dynamodb'], 'dynamo': ['dynamodb'], 'javascript': ['js', 'ecmascript', 'node', 'node.js'], 'js': ['javascript'], 'ecmascript': ['javascript'], 'node': ['javascript'], 'node.js': ['javascript'], 'typescript': ['ts', 'typescript lang'], 'ts': ['typescript'], 'typescript lang': ['typescript'], 'python': ['py', 'python3', 'python2', 'cpython'], 'py': ['python'], 'python3': ['python'], 'python2': ['python'], 'cpython': ['python'], 'java': ['jdk', 'jvm', 'java se', 'java ee'], 'jdk': ['java'], 'jvm': ['java'], 'java se': ['java'], 'java ee': ['java'], 'c#': ['csharp', 'c-sharp', '.net'], 'csharp': ['c#'], 'c-sharp': ['c#'], '.net': ['c#'], 'c++': ['cpp', 'c plus plus'], 'cpp': ['c++'], 'c plus plus': ['c++'], 'go': ['golang', 'go lang'], 'golang': ['go'], 'go lang': ['go'], 'ruby': ['rb', 'mri'], 'rb': ['ruby'], 'mri': ['ruby'], 'rust': ['rs', 'rust-lang'], 'rs': ['rust'], 'rust-lang': ['rust'], 'php': ['php7', 'php8'], 'php7': ['php'], 'php8': ['php'], 'swift': ['swift lang'], 'swift lang': ['swift'], 'kotlin': ['kt'], 'kt': ['kotlin'], 'react': ['reactjs', 'react.js', 'react native'], 'reactjs': ['react'], 'react.js': ['react'], 'react native': ['react'], 'vue.js': ['vue', 'vuejs', 'vue.js 2', 'vue.js 3'], 'vue': ['vue.js'], 'vuejs': ['vue.js'], 'vue.js 2': ['vue.js'], 'vue.js 3': ['vue.js'], 'angular': ['angularjs', 'ng', 'angular 2+'], 'angularjs': ['angular'], 'ng': ['angular'], 'angular 2+': ['angular'], 'django': ['django python', 'django framework'], 'django python': ['django'], 'django framework': ['django'], 'spring boot': ['spring', 'spring framework', 'spring boot'], 'spring': ['spring boot'], 'spring framework': ['spring boot'], 'ruby on rails': ['rails', 'ror'], 'rails': ['ruby on rails'], 'ror': ['ruby on rails'], 'laravel': ['laravel php'], 'laravel php': ['laravel'], 'express.js': ['express', 'expressjs'], 'express': ['express.js'], 'expressjs': ['express.js'], 'asp.net core': ['asp.net', '.net core', 'dotnet core'], 'asp.net': ['asp.net core'], '.net core': ['asp.net core'], 'dotnet core': ['asp.net core'], 'flutter': ['flutter sdk'], 'flutter sdk': ['flutter'], 'jquery': ['jquery', '$'], '$': ['jquery'], 'numpy': ['numpy'], 'pandas': ['pandas'], 'tensorflow': ['tf', 'tensorflow'], 'tf': ['tensorflow', 'terraform'], 'pytorch': ['torch', 'pytorch'], 'torch': ['pytorch'], 'redux': ['reduxjs'], 'reduxjs': ['redux'], 'tailwind css': ['tailwind', 'tailwindcss'], 'tailwind': ['tailwind css'], 'tailwindcss': ['tailwind css'], 'bootstrap': ['twitter bootstrap', 'bootstrap css'], 'twitter bootstrap': ['bootstrap'], 'bootstrap css': ['bootstrap'], 'git': ['git scm', 'git version control'], 'git scm': ['git'], 'git version control': ['git'], 'docker': ['docker container', 'docker engine'], 'docker container': ['docker'], 'docker engine': ['docker'], 'kubernetes': ['k8s', 'kube', 'kubectl'], 'k8s': ['kubernetes'], 'kube': ['kubernetes'], 'kubectl': ['kubernetes'], 'jenkins': ['jenkins ci'], 'jenkins ci': ['jenkins'], 'terraform': ['tf', 'hashicorp terraform'], 'hashicorp terraform': ['terraform'], 'ansible': ['ansible automation'], 'ansible automation': ['ansible'], 'visual studio code': ['vscode', 'vs code'], 'vscode': ['visual studio code'], 'vs code': ['visual studio code'], 'postman': ['postman api'], 'postman api': ['postman'], 'webpack': ['webpack bundler'], 'webpack bundler': ['webpack'], 'jira': ['atlassian jira'], 'atlassian jira': ['jira'], 'gitlab ci/cd': ['gitlab ci', 'gitlab cd'], 'gitlab ci': ['gitlab ci/cd'], 'gitlab cd': ['gitlab ci/cd'], 'windows': ['win', 'windows 10', 'windows 11', 'windows server'], 'win': ['windows'], 'windows 10': ['windows'], 'windows 11': ['windows'], 'windows server': ['windows'], 'macos': ['osx', 'mac os', 'darwin', 'apple os'], 'osx': ['macos'], 'mac os': ['macos'], 'darwin': ['macos'], 'apple os': ['macos'], 'linux': ['gnu/linux', 'ubuntu', 'debian', 'centos', 'red hat', 'rhel', 'fedora', 'alpine'], 'gnu/linux': ['linux'], 'ubuntu': ['linux'], 'debian': ['linux'], 'centos': ['linux'], 'red hat': ['linux'], 'rhel': ['linux'], 'fedora': ['linux'], 'alpine': ['linux'], 'android': ['android os'], 'android os': ['android'], 'ios': ['ios mobile', 'ipados'], 'ios mobile': ['ios'], 'ipados': ['ios'], 'unix': ['unix system'], 'unix system': ['unix'], 'amazon web services': ['aws', 'amazon cloud'], 'aws': ['amazon web services'], 'amazon cloud': ['amazon web services'], 'google cloud platform': ['gcp', 'google cloud'], 'gcp': ['google cloud platform'], 'google cloud': ['google cloud platform'], 'microsoft azure': ['azure', 'azure cloud'], 'azure': ['microsoft azure'], 'azure cloud': ['microsoft azure'], 'heroku': ['salesforce heroku'], 'salesforce heroku': ['heroku'], 'digitalocean': ['do', 'digital ocean'], 'do': ['digitalocean'], 'digital ocean': ['digitalocean'], 'ibm cloud': ['ibm bluemix'], 'ibm bluemix': ['ibm cloud'], 'oracle cloud': ['oci', 'oracle cloud infrastructure'], 'oci': ['oracle cloud'], 'oracle cloud infrastructure': ['oracle cloud']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "SKILLS_JSON_PATH = \"data/skills.json\"\n",
    "\n",
    "with open(SKILLS_JSON_PATH, \"r\") as f:\n",
    "    skills = json.load(f)\n",
    "    \n",
    "def create_bidirectional_graph(data):\n",
    "    \"\"\"\n",
    "    Flattens hierarchical JSON into a lowercase bidirectional map.\n",
    "    Key (Canonical) -> [Aliases]\n",
    "    Key (Alias)     -> [Canonical]\n",
    "    \"\"\"\n",
    "    bidirectional_map = {}\n",
    "\n",
    "    # Iterate through categories (databases, languages, etc.)\n",
    "    for category, tech_items in data.items():\n",
    "        for canonical_name, aliases in tech_items.items():\n",
    "            \n",
    "            # Normalize to lowercase for consistent lookup\n",
    "            canonical_key = canonical_name.lower()\n",
    "            alias_keys = [alias.lower() for alias in aliases]\n",
    "\n",
    "            # 1. Forward Link: Canonical -> [Aliases]\n",
    "            # e.g. \"javascript\" -> [\"js\", \"node\", ...]\n",
    "            if canonical_key not in bidirectional_map:\n",
    "                bidirectional_map[canonical_key] = []\n",
    "            \n",
    "            # Extend list, ensuring no duplicates\n",
    "            for alias in alias_keys:\n",
    "                if alias not in bidirectional_map[canonical_key]:\n",
    "                    bidirectional_map[canonical_key].append(alias)\n",
    "\n",
    "            # 2. Reverse Link: Alias -> [Canonical]\n",
    "            # e.g. \"js\" -> [\"javascript\"]\n",
    "            for alias in alias_keys:\n",
    "                if alias not in bidirectional_map:\n",
    "                    bidirectional_map[alias] = []\n",
    "                \n",
    "                if canonical_key not in bidirectional_map[alias]:\n",
    "                    bidirectional_map[alias].append(canonical_key)\n",
    "    \n",
    "    return bidirectional_map\n",
    "\n",
    "skills_graph = create_bidirectional_graph(skills)\n",
    "\n",
    "print(skills_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82378389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/repos/jobhunter/notebooks/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Semantic Skill Matching Module\n",
    "\n",
    "Uses sentence-transformers to match job skills against resume skills\n",
    "using semantic embeddings instead of exact string matching.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "\n",
    "class SkillMatch(BaseModel):\n",
    "    \"\"\"Result of matching a single job skill against resume.\"\"\"\n",
    "    skill_name: str                      # Job skill being checked\n",
    "    canonical_name: str                  # Matched resume skill (if found)\n",
    "    match_type: Literal[\"exact\", \"semantic\", \"text_evidence\", \"none\"]\n",
    "    is_matched: bool\n",
    "    confidence_score: float = 0.0        # 0.0-1.0 similarity score\n",
    "    evidence_source: str = \"\"            # Where the match was found\n",
    "\n",
    "\n",
    "class SemanticSkillMatcher:\n",
    "    \"\"\"\n",
    "    Semantic skill matcher using sentence embeddings.\n",
    "    \n",
    "    Example usage:\n",
    "        matcher = SemanticSkillMatcher()\n",
    "        \n",
    "        job_skills = [\"Java\", \"REST\", \"AWS\", \"CI/CD\", \"Mensageria\"]\n",
    "        resume_skills = [\"Python\", \"Java\", \"Spring Boot\", \"Docker\", \"RabbitMQ\"]\n",
    "        resume_text = \"Worked on REST APIs using FastAPI...\"\n",
    "        \n",
    "        matches = matcher.match_skills(job_skills, resume_skills, resume_text)\n",
    "        for m in matches:\n",
    "            print(m.model_dump())\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        strong_threshold: float = 0.75,\n",
    "        moderate_threshold: float = 0.60\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the semantic skill matcher.\n",
    "        \n",
    "        Args:\n",
    "            model_name: SentenceTransformer model to use\n",
    "            strong_threshold: Similarity >= this = strong match\n",
    "            moderate_threshold: Similarity >= this = moderate match\n",
    "        \"\"\"\n",
    "        print(f\"Loading embedding model: {model_name}...\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.strong_threshold = strong_threshold\n",
    "        self.moderate_threshold = moderate_threshold\n",
    "        print(\"Model loaded successfully!\")\n",
    "    \n",
    "    def match_skills(\n",
    "        self,\n",
    "        job_skills: list[str],\n",
    "        resume_skills: list[str],\n",
    "        resume_full_text: str = \"\"\n",
    "    ) -> list[SkillMatch]:\n",
    "        \"\"\"\n",
    "        Match job skills against resume using semantic embeddings.\n",
    "        \n",
    "        Args:\n",
    "            job_skills: Skills required in job posting\n",
    "            resume_skills: Explicit skills from resume\n",
    "            resume_full_text: Full resume text for evidence search\n",
    "        \n",
    "        Returns:\n",
    "            List of SkillMatch with confidence scores\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        # Pre-compute embeddings for all resume skills\n",
    "        resume_skill_embeddings = (\n",
    "            self.model.encode(resume_skills, convert_to_tensor=True) \n",
    "            if resume_skills else None\n",
    "        )\n",
    "        \n",
    "        # Embed full resume text for fallback evidence search\n",
    "        resume_text_embedding = (\n",
    "            self.model.encode(resume_full_text, convert_to_tensor=True)\n",
    "            if resume_full_text else None\n",
    "        )\n",
    "        \n",
    "        for job_skill in job_skills:\n",
    "            match = SkillMatch(\n",
    "                skill_name=job_skill,\n",
    "                canonical_name=\"\",\n",
    "                match_type=\"none\",\n",
    "                is_matched=False,\n",
    "                confidence_score=0.0,\n",
    "                evidence_source=\"\"\n",
    "            )\n",
    "            \n",
    "            job_skill_lower = job_skill.lower()\n",
    "            \n",
    "            # 1. Check exact match first (fastest)\n",
    "            for resume_skill in resume_skills:\n",
    "                if resume_skill.lower() == job_skill_lower:\n",
    "                    match.canonical_name = resume_skill\n",
    "                    match.match_type = \"exact\"\n",
    "                    match.is_matched = True\n",
    "                    match.confidence_score = 1.0\n",
    "                    match.evidence_source = \"resume_skills\"\n",
    "                    break\n",
    "            \n",
    "            # 2. If no exact match, try semantic matching against resume skills\n",
    "            if not match.is_matched and resume_skill_embeddings is not None:\n",
    "                job_skill_embedding = self.model.encode(job_skill, convert_to_tensor=True)\n",
    "                similarities = util.cos_sim(job_skill_embedding, resume_skill_embeddings)[0]\n",
    "                \n",
    "                best_idx = int(torch.argmax(similarities))\n",
    "                best_score = float(similarities[best_idx])\n",
    "                \n",
    "                if best_score >= self.moderate_threshold:\n",
    "                    match.canonical_name = resume_skills[best_idx]\n",
    "                    match.match_type = \"semantic\"\n",
    "                    match.is_matched = True\n",
    "                    match.confidence_score = round(best_score, 3)\n",
    "                    match.evidence_source = \"resume_skills\"\n",
    "            \n",
    "            # 3. Fallback: Check if skill is mentioned in full resume text\n",
    "            if not match.is_matched and resume_text_embedding is not None:\n",
    "                job_skill_embedding = self.model.encode(job_skill, convert_to_tensor=True)\n",
    "                text_similarity = float(\n",
    "                    util.cos_sim(job_skill_embedding, resume_text_embedding)[0][0]\n",
    "                )\n",
    "                \n",
    "                # Lower threshold for text evidence (less precise)\n",
    "                # Also check if the skill term appears directly in the text\n",
    "                skill_in_text = job_skill.lower() in resume_full_text.lower()\n",
    "                if text_similarity >= self.moderate_threshold * 0.75 or skill_in_text:\n",
    "                    match.canonical_name = \"(found in resume text)\" if skill_in_text else \"(inferred from experience)\"\n",
    "                    match.match_type = \"text_evidence\"\n",
    "                    match.is_matched = True\n",
    "                    match.confidence_score = round(text_similarity, 3)\n",
    "                    match.evidence_source = \"resume_text\"\n",
    "            \n",
    "            matches.append(match)\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def compare_skills(\n",
    "        self, \n",
    "        skill1: str, \n",
    "        skill2: str\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Compare two skills and return their semantic similarity.\n",
    "        \n",
    "        Useful for debugging/tuning thresholds.\n",
    "        \"\"\"\n",
    "        emb1 = self.model.encode(skill1, convert_to_tensor=True)\n",
    "        emb2 = self.model.encode(skill2, convert_to_tensor=True)\n",
    "        return float(util.cos_sim(emb1, emb2)[0][0])\n",
    "\n",
    "\n",
    "# Convenience function for quick usage\n",
    "def match_skills_semantic(\n",
    "    job_skills: list[str],\n",
    "    resume_skills: list[str],\n",
    "    resume_full_text: str,\n",
    "    matcher: SemanticSkillMatcher\n",
    ") -> list[SkillMatch]:\n",
    "    \"\"\"\n",
    "    Convenience wrapper for SemanticSkillMatcher.match_skills().\n",
    "    \n",
    "    Args:\n",
    "        job_skills: Skills required in job posting\n",
    "        resume_skills: Explicit skills from resume\n",
    "        resume_full_text: Full resume text for evidence search\n",
    "        matcher: SemanticSkillMatcher instance\n",
    "    \n",
    "    Returns:\n",
    "        List of SkillMatch with confidence scores\n",
    "    \"\"\"\n",
    "    return matcher.match_skills(job_skills, resume_skills, resume_full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bfaa65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: paraphrase-multilingual-MiniLM-L12-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 377.16it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Java            -> Java                      [exact        ] score=1.00\n",
      "Spring Boot     -> Spring Boot               [exact        ] score=1.00\n",
      "Web Services    ->                           [none         ] score=0.00\n",
      "REST            -> pika                      [semantic     ] score=0.71\n",
      "SOAP            ->                           [none         ] score=0.00\n",
      "Mensageria      -> pika                      [semantic     ] score=0.71\n",
      "Kubernetes      -> Kubernetes                [exact        ] score=1.00\n",
      "AWS             -> pika                      [semantic     ] score=0.64\n",
      "Docker          -> Docker                    [exact        ] score=1.00\n",
      "Oracle          -> SQL                       [semantic     ] score=0.63\n",
      "PostgreSQL      -> SQL                       [semantic     ] score=0.63\n",
      "DynamoDB        ->                           [none         ] score=0.00\n",
      "CI/CD           -> (found in resume text)    [text_evidence] score=0.07\n",
      "Git             -> Git                       [exact        ] score=1.00\n",
      "Jenkins         ->                           [none         ] score=0.00\n",
      "Github Actions  -> GitLab CI                 [semantic     ] score=0.66\n",
      "Node            ->                           [none         ] score=0.00\n"
     ]
    }
   ],
   "source": [
    "# Match resume skills with job description skills\n",
    "\n",
    "resume_skills = [] \n",
    "\n",
    "for skill in resume_data.skills:\n",
    "    resume_skills.extend(skill.keywords)\n",
    "\n",
    "job_skills = job_posting_data.required_hard_skills + job_posting_data.nice_to_have_skills\n",
    "\n",
    "matcher = SemanticSkillMatcher()\n",
    "skills_matches = match_skills_semantic(job_skills, resume_skills, resume_data.full_experience_text, matcher)\n",
    "\n",
    "for match in skills_matches:\n",
    "    print(f\"{match.skill_name:15} -> {match.canonical_name:25} \"\n",
    "          f\"[{match.match_type:13}] score={match.confidence_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17879c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "class CandidatePreferences(BaseModel):\n",
    "    minimum_salary: int # TODO: handle multi-currency\n",
    "    preferred_locations: List[Location] # TODO: improve this location model\n",
    "    work_arrangement: List[Literal['remote', 'hybrid', 'onsite']]\n",
    "\n",
    "candidate_preferences = CandidatePreferences(\n",
    "    minimum_salary=5000,\n",
    "    preferred_locations=[Location(\n",
    "        city=\"Maceio\",\n",
    "        state=\"Alagoas\",\n",
    "        country_code=\"BR\"\n",
    "    )],\n",
    "    work_arrangement=['remote', 'hybrid', 'onsite']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65d64ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrerequisiteMatch(category=<PrerequisiteType.YEARS_OF_EXPERIENCE: 'years_of_experience'>, is_mandatory=True, status=<MatchStatus.FAILED: 'failed'>, rationale='Candidate has 2.6 years. Job requires 5.', score=0.52), PrerequisiteMatch(category=<PrerequisiteType.DEGREE: 'degree'>, is_mandatory=False, status=<MatchStatus.PASSED: 'passed'>, rationale='Education requirements met.', score=1.0), PrerequisiteMatch(category=<PrerequisiteType.LOCATION: 'location'>, is_mandatory=True, status=<MatchStatus.FAILED: 'failed'>, rationale='No matching work arrangement or location found.', score=0.0), PrerequisiteMatch(category=<PrerequisiteType.SALARY: 'salary'>, is_mandatory=False, status=<MatchStatus.NEUTRAL: 'neutral'>, rationale='Salary not disclosed in job posting.', score=0.0)]\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Literal, Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "import dateutil.parser # pip install python-dateutil\n",
    "\n",
    "# --- Enums ---\n",
    "class PrerequisiteType(str, Enum):\n",
    "    DEGREE = \"degree\"\n",
    "    YEARS_OF_EXPERIENCE = \"years_of_experience\"\n",
    "    SKILLS = \"skills\"\n",
    "    LOCATION = \"location\"\n",
    "    LANGUAGE = \"language\"\n",
    "    SALARY = \"salary\"\n",
    "\n",
    "class MatchStatus(str, Enum):\n",
    "    PASSED = \"passed\"\n",
    "    FAILED = \"failed\"\n",
    "    WARNING = \"warning\" # For partial matches or missing info\n",
    "    NEUTRAL = \"neutral\" # When info is missing but not mandatory\n",
    "\n",
    "# --- Output Schema ---\n",
    "class PrerequisiteMatch(BaseModel):\n",
    "    category: PrerequisiteType\n",
    "    is_mandatory: bool\n",
    "    status: MatchStatus\n",
    "    rationale: str\n",
    "    score: float = 0.0 # 0.0 to 1.0 (Useful for ranking)\n",
    "\n",
    "def calculate_years_of_experience(work_history: List[Work]) -> float:\n",
    "    total_days = 0\n",
    "    \n",
    "    for job in work_history:\n",
    "        if not job.start_date:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            start = dateutil.parser.parse(job.start_date)\n",
    "            \n",
    "            if job.end_date and job.end_date.lower() != \"current\":\n",
    "                end = dateutil.parser.parse(job.end_date)\n",
    "            else:\n",
    "                end = datetime.now()\n",
    "                \n",
    "            delta = end - start\n",
    "            total_days += delta.days\n",
    "        except Exception:\n",
    "            # If date parsing fails, skip this entry or assume 0\n",
    "            continue\n",
    "            \n",
    "    return round(total_days / 365.25, 1)\n",
    "\n",
    "def match_prerequisites(\n",
    "    job: JobPostingSchema, \n",
    "    preferences: CandidatePreferences, \n",
    "    resume: ResumeSchema\n",
    ") -> List[PrerequisiteMatch]:\n",
    "    \n",
    "    matches = []\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. YEARS OF EXPERIENCE\n",
    "    # ---------------------------------------------------------\n",
    "    candidate_years = calculate_years_of_experience(resume.work)\n",
    "    exp_status = MatchStatus.PASSED\n",
    "    exp_rationale = f\"Candidate has {candidate_years} years. Job requires {job.min_experience_years}.\"\n",
    "    \n",
    "    if candidate_years < job.min_experience_years:\n",
    "        # Allow a small buffer (e.g., 0.5 years) to be 'WARNING' instead of 'FAILED'\n",
    "        if candidate_years >= (job.min_experience_years - 0.5):\n",
    "            exp_status = MatchStatus.WARNING\n",
    "        else:\n",
    "            exp_status = MatchStatus.FAILED\n",
    "    \n",
    "    matches.append(PrerequisiteMatch(\n",
    "        category=PrerequisiteType.YEARS_OF_EXPERIENCE,\n",
    "        is_mandatory=True,\n",
    "        status=exp_status,\n",
    "        rationale=exp_rationale,\n",
    "        score=min(candidate_years / job.min_experience_years, 1.0) if job.min_experience_years > 0 else 1.0\n",
    "    ))\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. DEGREE / EDUCATION\n",
    "    # ---------------------------------------------------------\n",
    "    # Logic: If job requires degree, check if 'education' list is not empty.\n",
    "    # Advanced: specific parsing for 'Bachelor', 'Master' in study_type.\n",
    "    degree_status = MatchStatus.PASSED\n",
    "    degree_rationale = \"Education requirements met.\"\n",
    "    \n",
    "    if job.degree_required:\n",
    "        if not resume.education:\n",
    "            degree_status = MatchStatus.FAILED\n",
    "            degree_rationale = \"Job requires a degree, but no education listed.\"\n",
    "        else:\n",
    "            # Check for 'Bachelor' or higher keywords if needed\n",
    "            has_higher_ed = any(\n",
    "                term in edu.study_type.lower() \n",
    "                for edu in resume.education \n",
    "                for term in ['bachelor', 'master', 'phd', 'mba', 'gradu', 'bacharel', 'licenciatura']\n",
    "            )\n",
    "            if not has_higher_ed:\n",
    "                degree_status = MatchStatus.WARNING\n",
    "                degree_rationale = \"Higher education listed, but specific degree type not detected.\"\n",
    "\n",
    "    matches.append(PrerequisiteMatch(\n",
    "        category=PrerequisiteType.DEGREE,\n",
    "        is_mandatory=job.degree_required,\n",
    "        status=degree_status,\n",
    "        rationale=degree_rationale,\n",
    "        score=1.0 if degree_status == MatchStatus.PASSED else 0.0\n",
    "    ))\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. LOCATION & WORK MODEL\n",
    "    # ---------------------------------------------------------\n",
    "    # Logic: Intersection of Job Options vs Candidate Preferences + Current Location\n",
    "    loc_status = MatchStatus.FAILED\n",
    "    loc_rationale = \"No matching work arrangement or location found.\"\n",
    "    \n",
    "    candidate_city = resume.basics.location.city.lower() if resume.basics.location and resume.basics.location.city else \"\"\n",
    "    pref_cities = [l.city.lower() for l in preferences.preferred_locations if l.city]\n",
    "    \n",
    "    # Check each option provided by the job\n",
    "    for option in job.work_options:\n",
    "        # 1. Remote Check\n",
    "        if option.model == 'remote' and 'remote' in preferences.work_arrangement:\n",
    "            loc_status = MatchStatus.PASSED\n",
    "            loc_rationale = \"Matches REMOTE preference.\"\n",
    "            break\n",
    "            \n",
    "        # 2. Hybrid/Onsite Check\n",
    "        if option.model in ['hybrid', 'onsite'] and option.model in preferences.work_arrangement:\n",
    "            job_city = option.city.lower() if option.city else \"\"\n",
    "            \n",
    "            # Match if candidate is already there OR wants to be there\n",
    "            if job_city == candidate_city or job_city in pref_cities:\n",
    "                loc_status = MatchStatus.PASSED\n",
    "                loc_rationale = f\"Matches {option.model.upper()} in {option.city}.\"\n",
    "                break\n",
    "    \n",
    "    matches.append(PrerequisiteMatch(\n",
    "        category=PrerequisiteType.LOCATION,\n",
    "        is_mandatory=True, # Usually mandatory unless relocation is offered\n",
    "        status=loc_status,\n",
    "        rationale=loc_rationale,\n",
    "        score=1.0 if loc_status == MatchStatus.PASSED else 0.0\n",
    "    ))\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. SALARY\n",
    "    # ---------------------------------------------------------\n",
    "    sal_status = MatchStatus.NEUTRAL\n",
    "    sal_rationale = \"Salary not disclosed in job posting.\"\n",
    "    \n",
    "    if job.salary and job.salary.max_amount:\n",
    "        # Check if Job Max < Candidate Min\n",
    "        if job.salary.max_amount < preferences.minimum_salary:\n",
    "            sal_status = MatchStatus.FAILED\n",
    "            sal_rationale = f\"Job max ({job.salary.max_amount}) is below candidate minimum ({preferences.minimum_salary}).\"\n",
    "        else:\n",
    "            sal_status = MatchStatus.PASSED\n",
    "            sal_rationale = \"Salary expectations met.\"\n",
    "            \n",
    "    matches.append(PrerequisiteMatch(\n",
    "        category=PrerequisiteType.SALARY,\n",
    "        is_mandatory=False, # Often negotiable\n",
    "        status=sal_status,\n",
    "        rationale=sal_rationale,\n",
    "        score=1.0 if sal_status == MatchStatus.PASSED else 0.0\n",
    "    ))\n",
    "\n",
    "    return matches\n",
    "\n",
    "prerequisites_matches = match_prerequisites(\n",
    "    job = job_posting_data, \n",
    "    preferences = candidate_preferences, \n",
    "    resume = resume_data\n",
    ")\n",
    "print(prerequisites_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca308e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class EvaluationPoint(BaseModel):\n",
    "    category: Literal[\"Technical Depth\", \"Leadership\", \"Culture\", \"Project Relevance\"]\n",
    "    description: str = Field(..., description=\"Explain the point clearly\")\n",
    "    evidence: str = Field(..., description=\"Quote specific part of resume or job to support this\")\n",
    "\n",
    "class SemanticAnalysis(BaseModel):\n",
    "    # O Veredito resume a impressão geral\n",
    "    verdict: Literal[\"Strong Match\", \"Potential Match\", \"Weak Match\", \"Not a Fit\"]\n",
    "    \n",
    "    # Pontos Fortes: Onde o candidato brilha em relação à vaga\n",
    "    strengths: List[EvaluationPoint] = Field(..., description=\"Aspects where candidate exceeds or perfectly meets requirements\")\n",
    "    \n",
    "    # Pontos Fracos: Gaps técnicos ou de experiência\n",
    "    weaknesses: List[EvaluationPoint] = Field(..., description=\"Missing skills or insufficient experience depth\")\n",
    "    \n",
    "    # Pontos de Atenção: Coisas para perguntar na entrevista\n",
    "    interview_questions: List[str] = Field(..., description=\"Specific questions to probe the red flags/ambiguities\")\n",
    "    \n",
    "    # Análise de Soft Skills (Inferida do texto)\n",
    "    soft_skills_analysis: str = Field(..., description=\"Brief analysis of communication, leadership, and drive based on project descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6eb3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_resume_for_llm(resume: ResumeSchema) -> str:\n",
    "    text = f\"CANDIDATE: ({resume.basics.label})\\n\\n\"\n",
    "\n",
    "    if resume.basics.summary:\n",
    "        text += f\"SUMMARY:\\n{resume.basics.summary}\\n\"\n",
    "    \n",
    "    text += \"WORK HISTORY:\\n\"\n",
    "    for work in resume.work:\n",
    "        text += f\"- {work.position} at {work.name} ({work.start_date} to {work.end_date})\\n\"\n",
    "        text += f\"  Summary: {work.summary}\\n\"\n",
    "        text += f\"  Highlights: {'; '.join(work.highlights)}\\n\\n\"\n",
    "        \n",
    "    text += \"PROJECTS:\\n\"\n",
    "    for proj in resume.projects:\n",
    "        text += f\"- {proj.name}: {proj.description}\\n\"\n",
    "        text += f\"  Stack: {', '.join(proj.keywords)}\\n\"\n",
    "        \n",
    "    return text\n",
    "\n",
    "def analyze_semantic_match(\n",
    "    job: JobPostingSchema, \n",
    "    resume: ResumeSchema, \n",
    "    skill_matches: list[SkillMatch],\n",
    "    prerequisites: list[PrerequisiteMatch],\n",
    "    client\n",
    ") -> SemanticAnalysis:\n",
    "    \n",
    "    # 1. Prepare resume text\n",
    "    resume_text = format_resume_for_llm(resume)\n",
    "    \n",
    "    # 2. Prepare job context\n",
    "    job_context = f\"\"\"\n",
    "    JOB TITLE: {job.title}\n",
    "    SENIORITY: {', '.join([s.name for s in job.seniority_level])}\n",
    "\n",
    "    KEY RESPONSIBILITIES:\n",
    "    {chr(10).join(['- ' + r for r in job.key_responsibilities])}\n",
    "\n",
    "    SOFT SKILLS DESIRED:\n",
    "    {', '.join(job.soft_skills_context)}\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. Format pre-computed matching data\n",
    "    matched_skills = [m for m in skill_matches if m.is_matched]\n",
    "    missing_skills = [m.skill_name for m in skill_matches if not m.is_matched]\n",
    "    alias_matches = [f\"{m.skill_name} → {m.canonical_name}\" for m in skill_matches if m.match_type == \"alias\"]\n",
    "    \n",
    "    match_percentage = (len(matched_skills) / len(skill_matches) * 100) if skill_matches else 0\n",
    "    \n",
    "    prereq_summary = \"\\n\".join([\n",
    "        f\"- {p.category.value}: {p.status.value} ({p.rationale})\" \n",
    "        for p in prerequisites\n",
    "    ])\n",
    "\n",
    "    # 4. Build the enhanced prompt\n",
    "    prompt = f\"\"\"You are an expert Technical Recruiter with 15+ years of experience screening candidates.\n",
    "    ---\n",
    "    ## JOB CONTEXT\n",
    "    {job_context}\n",
    "\n",
    "    ---\n",
    "    ## CANDIDATE RESUME\n",
    "    {resume_text}\n",
    "\n",
    "    ---\n",
    "    ## PRE-COMPUTED MATCHING DATA (Trust these as facts)\n",
    "\n",
    "    ### Skills Match: {len(matched_skills)}/{len(skill_matches)} ({match_percentage:.0f}%)\n",
    "    - Missing Required Skills: {', '.join(missing_skills) if missing_skills else 'None'}\n",
    "    - Skills Matched via Alias: {', '.join(alias_matches) if alias_matches else 'None'}\n",
    "\n",
    "    ### Prerequisites Check:\n",
    "    {prereq_summary}\n",
    "\n",
    "    ---\n",
    "    ## EVALUATION INSTRUCTIONS\n",
    "\n",
    "    1. **ROLE ALIGNMENT**: Compare career trajectory. Developer vs Manager = mismatch.\n",
    "    2. **EVIDENCE ONLY**: Accept concrete actions (\"Led\", \"Built\", \"Reduced X by Y%\"). Reject vague claims.\n",
    "    3. **USE THE DATA**: The skill matches above are FACTS. Focus your analysis on:\n",
    "    - Are the missing skills critical blockers or quickly learnable?\n",
    "    - Does experience DEPTH match the role, not just keywords?\n",
    "    - What specific concerns should be probed in an interview?\n",
    "\n",
    "    ### SCORING CRITERIA\n",
    "    - **Strong Match**: 80%+ skills, matching seniority, proven impact\n",
    "    - **Potential Match**: 60%+ skills, 1 level gap, transferable experience  \n",
    "    - **Weak Match**: Major gaps OR career mismatch OR insufficient depth\n",
    "    - **Not a Fit**: Fundamental misalignment\n",
    "\n",
    "    Be STRICT. When in doubt, rate DOWN.\n",
    "\n",
    "    Provide your analysis in the SemanticAnalysis JSON format.\"\"\"\n",
    "\n",
    "    # 5. Call LLM\n",
    "    try:\n",
    "        response_data, _ = client.chat.completions.create_with_completion(\n",
    "            model=\"gemma-3-27b-it\", \n",
    "            response_model=SemanticAnalysis,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error in semantic analysis: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f541291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"verdict\": \"Weak Match\",\n",
      "    \"strengths\": [\n",
      "        {\n",
      "            \"category\": \"Technical Depth\",\n",
      "            \"description\": \"The candidate demonstrates experience with microservices architecture, containerization (Docker), and CI/CD pipelines (GitLab, Kubernetes). This aligns with key responsibilities outlined in the job description.\",\n",
      "            \"evidence\": \"Participated in deploying applications to the client's internal environment, ensuring security and quality standards through containerization (Docker), CI/CD pipeline creation (GitLab), and Kubernetes orchestration\"\n",
      "        },\n",
      "        {\n",
      "            \"category\": \"Technical Depth\",\n",
      "            \"description\": \"Experience with messaging queues (RabbitMQ) is a positive, indicating familiarity with asynchronous processing, which is relevant to the 'Mensageria' requirement.\",\n",
      "            \"evidence\": \"Implemented a messaging pipeline with RabbitMQ for asynchronous processing of ML/LLM jobs between microservices, ensuring delivery and decoupling\"\n",
      "        },\n",
      "        {\n",
      "            \"category\": \"Project Relevance\",\n",
      "            \"description\": \"The 'Odontolog' project demonstrates practical Java and Spring Boot experience, directly aligning with the core technology stack.\",\n",
      "            \"evidence\": \"Odontolog: Backend development for a university dental school clinic management system. Stack: Java, Spring Boot, PostgreSQL, Docker\"\n",
      "        }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "        {\n",
      "            \"category\": \"Technical Depth\",\n",
      "            \"description\": \"Significant gaps in required skills exist, specifically Web Services (REST/SOAP), AWS, and potentially specific messaging technologies beyond RabbitMQ. These are critical for the role.\",\n",
      "            \"evidence\": \"Missing Required Skills: Web Services, REST, SOAP, Mensageria, AWS\"\n",
      "        },\n",
      "        {\n",
      "            \"category\": \"Technical Depth\",\n",
      "            \"description\": \"The candidate's experience is primarily in Python/FastAPI, with Java experience limited to a single project. The job description heavily emphasizes Java.\",\n",
      "            \"evidence\": \"WORK HISTORY focuses on Python/FastAPI. 'Odontolog' is the only Java project listed.\"\n",
      "        },\n",
      "        {\n",
      "            \"category\": \"Technical Depth\",\n",
      "            \"description\": \"The candidate lacks the required years of experience (5 years) with only 2.6 years of experience. This is a significant blocker.\",\n",
      "            \"evidence\": \"years_of_experience: failed (Candidate has 2.6 years. Job requires 5.)\"\n",
      "        },\n",
      "        {\n",
      "            \"category\": \"Technical Depth\",\n",
      "            \"description\": \"The candidate's location/work arrangement doesn't match the job requirements.\",\n",
      "            \"evidence\": \"location: failed (No matching work arrangement or location found.)\"\n",
      "        }\n",
      "    ],\n",
      "    \"interview_questions\": [\n",
      "        \"Can you elaborate on your experience with RESTful web services? Describe a project where you designed and implemented a REST API.\",\n",
      "        \"What is your understanding of SOAP web services? Have you worked with them, and if so, in what capacity?\",\n",
      "        \"Describe your experience with AWS services. Which services have you used, and for what purposes?\",\n",
      "        \"The job description mentions 'Mensageria'. Beyond RabbitMQ, are you familiar with other messaging technologies like Kafka or ActiveMQ?\",\n",
      "        \"Given your experience is primarily in Python, how quickly do you anticipate being able to contribute effectively to a Java-based project?\",\n",
      "        \"Can you describe a time you had to troubleshoot a complex issue in a microservices environment? What tools and techniques did you use?\"\n",
      "    ],\n",
      "    \"soft_skills_analysis\": \"The candidate demonstrates analytical skills through refactoring code for testability and implementing observability solutions. Their contributions to increasing test coverage suggest a commitment to quality. The project descriptions indicate a proactive approach to problem-solving and a willingness to learn new technologies (RAG pipelines, LLMs). However, the resume lacks explicit examples of communication, resilience, or leadership.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "semantic_match = analyze_semantic_match(job_posting_data, resume_data, skills_matches, prerequisites_matches, client)\n",
    "\n",
    "print(semantic_match.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d3de298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def __init__(self, ai_client, skills_graph):\n",
    "        self.client = ai_client\n",
    "        self.skills_graph = skills_graph\n",
    "        self.skill_matcher = SemanticSkillMatcher()\n",
    "\n",
    "    def run(self, job_text: str, resume_json: dict):\n",
    "        print(\"⚙️ 1. Starting Pipeline...\")\n",
    "        \n",
    "        # 1. Parsing\n",
    "        print(\"📄 Extracting Job Data...\")\n",
    "        job_data = extract_job_data(job_text)\n",
    "        \n",
    "        print(\"👤 Processing Resume...\")\n",
    "        resume_data: ResumeSchema = ResumeSchema.model_validate(resume_json)  # Fixed: use model_validate\n",
    "        \n",
    "        # 2. Logical Filters\n",
    "        print(\"🛡️ Checking Prerequisites...\")\n",
    "        prefs = CandidatePreferences(\n",
    "            minimum_salary=0, \n",
    "            preferred_locations=[], \n",
    "            work_arrangement=[\"remote\", \"hybrid\", \"onsite\"]\n",
    "        )\n",
    "        prereqs = match_prerequisites(job_data, prefs, resume_data)\n",
    "\n",
    "        # 3. Skills Graph\n",
    "        print(\"🔗 Checking Skills in Graph...\")\n",
    "        job_skills = job_data.required_hard_skills\n",
    "        resume_skills_list = list(resume_data.all_hard_skills)\n",
    "        resume_full_text = resume_data.full_experience_text\n",
    "        skill_matches = self.skill_matcher.match_skills(job_skills, resume_skills, resume_full_text)\n",
    "        \n",
    "        # 4. Semantic AI (now with pre-computed data!)\n",
    "        print(\"🧠 Performing Semantic Analysis...\")\n",
    "        semantic_res = analyze_semantic_match(\n",
    "            job_data, \n",
    "            resume_data, \n",
    "            skill_matches,      # Pass skill matches\n",
    "            prereqs,            # Pass prerequisites\n",
    "            self.client\n",
    "        )\n",
    "        \n",
    "        # 5. Final Score\n",
    "        print(\"📊 Calculating Score...\")\n",
    "        \n",
    "        verdict_map = {\"Strong Match\": 95, \"Potential Match\": 75, \"Weak Match\": 40, \"Not a Fit\": 10}\n",
    "        sem_score = verdict_map.get(semantic_res.verdict, 50)\n",
    "        \n",
    "        tech_score = 100\n",
    "        if job_skills:\n",
    "            matches = sum(1 for m in skill_matches if m.is_matched)\n",
    "            tech_score = (matches / len(job_skills)) * 100\n",
    "            \n",
    "        prereq_score = 100 if all(p.status == MatchStatus.PASSED for p in prereqs) else 0\n",
    "        \n",
    "        final_score = (prereq_score * 0.2) + (tech_score * 0.3) + (sem_score * 0.5)\n",
    "        \n",
    "        return {\n",
    "            \"Total Score\": round(final_score, 1),\n",
    "            \"Verdict\": semantic_res.verdict,\n",
    "            \"Prereq Score\": round(prereq_score, 1),\n",
    "            \"Tech Score\": round(tech_score, 1),\n",
    "            \"Semantic Score\": sem_score,\n",
    "            \"Strengths\": [s.description for s in semantic_res.strengths],\n",
    "            \"Weaknesses\": [w.description for w in semantic_res.weaknesses],\n",
    "            \"Interview Questions\": semantic_res.interview_questions,\n",
    "            \"Feedback\": semantic_res.soft_skills_analysis\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59c7e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: paraphrase-multilingual-MiniLM-L12-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 382.69it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "⚙️ 1. Starting Pipeline...\n",
      "📄 Extracting Job Data...\n",
      "title='Engenheiro de Software Junior ou Pleno (Java) | Investment Products' company_name='BTG Pactual' original_url=None seniority_level=[<SeniorityLevel.JR: 1>, <SeniorityLevel.MID: 2>] work_options=[JobWorkplace(model='hybrid', country='BR', state='SP', city='São Paulo')] required_hard_skills=['Java', 'Spring Boot', 'Web Services', 'REST', 'SOAP', 'Mensageria', 'Kubernetes', 'AWS', 'Docker', 'Oracle', 'PostgreSQL', 'DynamoDB', 'CI/CD', 'Git', 'Jenkins', 'Github Actions'] nice_to_have_skills=['Node'] min_experience_years=0 degree_required=True languages=[] key_responsibilities=['Referência técnica e atuação junto à equipe de projetos que utiliza em seu trabalho algumas tecnologias como Java, Spring Boot, WebServices REST/SOAP, Mensageria, Kubernetes e AWS.', 'Trabalhar com arquitetura orientada a microsserviços, modelo DevOps e experiência com troubleshooting e análise de logs.', 'Desenvolver e expandir do pipeline de produtos do Portal de Clientes do BTG e soluções para a plataforma administrativa', 'Atuar nos projetos que consistem em aumentar e flexibilizar produtos disponíveis na plataforma Digital.'] soft_skills_context=['comunicação', 'resiliência', 'analítica', 'crescimento profissional', 'superar desafios', 'inovação'] benefits_text='Participação nos Lucros e Resultados (PLR);\\nAuxílio Alimentação e Refeição;\\nPlano Médico;\\nPlano Odontológico;\\nAuxílio Creche/Babá;\\nVale Transporte;\\nWellHub;\\nTotalPass;\\nPrograma de Apoio Pessoal (EAP);\\nPlanos por adesão como Previdência Privada e Seguro de Vida;\\nDesconto em Farmácia;\\nPrograma de Nutrição;\\nPrograma de Gestantes;\\nLicença Maternidade e Paternidade Estendida – empresa Cidadã.' salary=None\n",
      "DEBUG: ChatCompletion(id='BgaEaamwCrHqz7IP3qKK0QM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"title\": \"Engenheiro de Software Junior ou Pleno (Java) | Investment Products\",\\n  \"company_name\": \"BTG Pactual\",\\n  \"original_url\": null,\\n  \"seniority_level\": [\\n    1,\\n    2\\n  ],\\n  \"work_options\": [\\n    {\\n      \"model\": \"hybrid\",\\n      \"country\": \"BR\",\\n      \"state\": \"SP\",\\n      \"city\": \"São Paulo\"\\n    }\\n  ],\\n  \"required_hard_skills\": [\\n    \"Java\",\\n    \"Spring Boot\",\\n    \"Web Services\",\\n    \"REST\",\\n    \"SOAP\",\\n    \"Mensageria\",\\n    \"Kubernetes\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Oracle\",\\n    \"PostgreSQL\",\\n    \"DynamoDB\",\\n    \"CI/CD\",\\n    \"Git\",\\n    \"Jenkins\",\\n    \"Github Actions\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Node\"\\n  ],\\n  \"min_experience_years\": 0,\\n  \"degree_required\": true,\\n  \"languages\": [],\\n  \"key_responsibilities\": [\\n    \"Referência técnica e atuação junto à equipe de projetos que utiliza em seu trabalho algumas tecnologias como Java, Spring Boot, WebServices REST/SOAP, Mensageria, Kubernetes e AWS.\",\\n    \"Trabalhar com arquitetura orientada a microsserviços, modelo DevOps e experiência com troubleshooting e análise de logs.\",\\n    \"Desenvolver e expandir do pipeline de produtos do Portal de Clientes do BTG e soluções para a plataforma administrativa\",\\n    \"Atuar nos projetos que consistem em aumentar e flexibilizar produtos disponíveis na plataforma Digital.\"\\n  ],\\n  \"soft_skills_context\": [\\n    \"comunicação\",\\n    \"resiliência\",\\n    \"analítica\",\\n    \"crescimento profissional\",\\n    \"superar desafios\",\\n    \"inovação\"\\n  ],\\n  \"benefits_text\": \"Participação nos Lucros e Resultados (PLR);\\\\nAuxílio Alimentação e Refeição;\\\\nPlano Médico;\\\\nPlano Odontológico;\\\\nAuxílio Creche/Babá;\\\\nVale Transporte;\\\\nWellHub;\\\\nTotalPass;\\\\nPrograma de Apoio Pessoal (EAP);\\\\nPlanos por adesão como Previdência Privada e Seguro de Vida;\\\\nDesconto em Farmácia;\\\\nPrograma de Nutrição;\\\\nPrograma de Gestantes;\\\\nLicença Maternidade e Paternidade Estendida – empresa Cidadã.\",\\n  \"salary\": null\\n}\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1770259974, model='gemma-3-12b-it', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=0, prompt_tokens=2026, total_tokens=2026, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "👤 Processing Resume...\n",
      "🛡️ Checking Prerequisites...\n",
      "🔗 Checking Skills in Graph...\n",
      "🧠 Performing Semantic Analysis...\n",
      "📊 Calculating Score...\n",
      "\n",
      "==================================================\n",
      "🏆 FINAL SCORE: 60.0%\n",
      "⚖️ VERDICT: Potential Match\n",
      "💻 PREREQ SCORE: 0%\n",
      "💻 TECH SCORE: 75.0%\n",
      "🧠 SEMANTIC SCORE: 75\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ✅ Strong Points:\n",
       "- The candidate demonstrates solid experience with Java and Spring Boot, as evidenced by their work on the 'Odontolog' project and their contributions at Centro de Inovação EDGE.\n",
       "- Experience with microservices architecture, messaging queues (RabbitMQ), containerization (Docker), and CI/CD pipelines (GitLab) aligns well with the job description's requirements.\n",
       "- The candidate's focus on testability and code quality (90% test coverage, applying design patterns) is a positive indicator of their engineering practices."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 🛑 Weak Points:\n",
       "- The candidate lacks explicit experience with Web Services (SOAP specifically) as indicated by the skills match. While they have REST API experience (FastAPI), SOAP is a specific requirement.\n",
       "- The candidate has no listed experience with DynamoDB, which is a required skill. This is a potential blocker depending on the importance of DynamoDB in the role.\n",
       "- The candidate lacks experience with Jenkins. While they use GitLab for CI/CD, familiarity with Jenkins could be beneficial.\n",
       "- The candidate's location is not a match, indicating a potential issue with work arrangement or location preferences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ❓ Interview Questions:\n",
       "- Can you describe your experience with SOAP web services? If limited, how quickly do you think you could get up to speed?\n",
       "- What is your understanding of DynamoDB and its use cases? Have you worked with any NoSQL databases?\n",
       "- Describe your experience with CI/CD pipelines. How does GitLab compare to Jenkins in your experience?\n",
       "- Can you elaborate on your experience with troubleshooting and analyzing logs in a microservices environment?\n",
       "- Tell me about a time you had to learn a new technology quickly to solve a problem. What was your approach?\n",
       "- What are your location preferences and are you open to remote work or relocation?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 💬 Soft Skills Feedback:\n",
       "The candidate demonstrates analytical skills through their focus on observability (logging, error tracking) and test coverage. Their work on refactoring and implementing design patterns suggests a desire for code quality and maintainability. The project descriptions don't provide much insight into communication or leadership skills, but their contributions to multiple areas within projects suggest a proactive and engaged team member."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engine = Engine(client, skills_graph)\n",
    "result = engine.run(job_text, resume_json)\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"🏆 FINAL SCORE: {result['Total Score']}%\")\n",
    "print(f\"⚖️ VERDICT: {result['Verdict']}\")\n",
    "print(f\"💻 PREREQ SCORE: {result['Prereq Score']}%\")\n",
    "print(f\"💻 TECH SCORE: {result['Tech Score']}%\")\n",
    "print(f\"🧠 SEMANTIC SCORE: {result['Semantic Score']}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "display(Markdown(f\"### ✅ Strong Points:\\n\" + \"\\n\".join([f\"- {s}\" for s in result['Strengths']])))\n",
    "display(Markdown(f\"### 🛑 Weak Points:\\n\" + \"\\n\".join([f\"- {w}\" for w in result['Weaknesses']])))\n",
    "display(Markdown(f\"### ❓ Interview Questions:\\n\" + \"\\n\".join([f\"- {q}\" for q in result['Interview Questions']])))\n",
    "display(Markdown(f\"### 💬 Soft Skills Feedback:\\n{result['Feedback']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
